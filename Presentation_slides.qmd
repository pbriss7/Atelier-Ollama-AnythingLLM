---
title: "Utiliser des LLMs ouverts avec Ollama et AnythingLLM"
subtitle: "Atelier pratique - AI Horizons in Language Learning"
author: "Pascal Brissette"
date: "25 Novembre 2025"
format:
  revealjs:
    theme: simple
    slide-number: true
    chalkboard: true
    preview-links: auto
    logo: images/logo.png
    footer: "Atelier Ollama & AnythingLLM | 25 nov. 2025"
---

# Introduction {background-color="#2C3E50"}

## L'IA générative en 2025

::: {.incremental}
- ChatGPT (2022) : démocratisation de l'IA
- Accessible aux non-spécialistes
- Nouveaux paradigmes en enseignement
- **Mais à quel prix?**
:::

## Les coûts cachés de l'IA

::: {.columns}
::: {.column width="50%"}
**Environnemental**

- 4,4% de l'électricité US (2023)
- Projection : 20% mondial (2030-2035)
- 5+ milliards litres d'eau (Google, 2022)
:::

::: {.column width="50%"}
**Humain**

- Travail précaire d'étiquetage
- Exposition à contenus toxiques
- Exploitation des plus vulnérables
:::
:::

## Les coûts cachés (suite)

**Légal et éthique**

- Violation du droit d'auteur
- Anthropic : 1,5 milliard $ (2025)
- Confidentialité des données

::: {.callout-warning}
Les plateformes gratuites monétisent vos données!
:::

## Notre solution : Ollama + AnythingLLM

::: {.incremental}
✅ Modèles **moins énergivores**

✅ Énergie **québécoise** (sans GES)

✅ **Confidentialité** totale (local ou cloud sécurisé)

✅ **Gratuit** et open source
:::

# Les outils {background-color="#2C3E50"}

## Ollama : la passerelle

![](images/clipboard-3253480821.png){width=60%}

::: {.incremental}
- Bibliothèque locale de modèles
- Interface simple
- Garantie de confidentialité
- Compatible Mac, Windows, Linux
:::

## AnythingLLM : l'interface

![](images/clipboard-521951548.png){width=60%}

::: {.incremental}
- Interface graphique intuitive
- Paramétrage avancé
- Compatible avec Ollama
- Base de données locale (RAG)
:::

## La métaphore théâtrale

::: {.r-fit-text}
**AnythingLLM** = la scène (visible, contrôlable)

**Ollama** = la régie (en coulisses, essentiel)
:::

## Modèles locaux vs distants

::: {.columns}
::: {.column width="50%"}
**Locaux**

- Sur votre ordinateur
- Espace disque requis
- Confidentialité absolue
- Ex: `gemma3:1b` (815 MB)
:::

::: {.column width="50%"}
**Distants (cloud)**

- Serveurs Ollama
- Pas d'espace requis
- Même confidentialité
- Ex: `gpt-oss:120b-cloud`
:::
:::

# Première partie : Installation {background-color="#2C3E50"}

## ⚙️ Installer Ollama

1. Aller sur **ollama.com**
2. Télécharger pour votre OS
3. Créer un compte (gratuit)

::: {.callout-tip}
Le compte est nécessaire uniquement pour les modèles cloud
:::

## ⚙️ Installer AnythingLLM

1. Aller sur **anythingllm.com/desktop**
2. Télécharger l'application
3. Installer

::: {.fragment}
⏸️ **PAUSE TECHNIQUE** (5 min)

*Assurons-nous que tout le monde a installé les deux outils*
:::

## Télécharger un modèle léger

**Dans Ollama :**

1. Cliquer sur `Select model`
2. Taper : `gemma3:1b`
3. Poser une question : "Qui es-tu?"
4. Appuyer sur `Enter`

::: {.callout-note}
Le téléchargement démarre automatiquement (815 MB)
:::

## Activer un modèle cloud

**Même procédure :**

1. `Select model`
2. Taper : `gpt-oss:20b-cloud` ☁️
3. Tester avec une question

::: {.fragment}
Repérer les modèles cloud : cherchez l'icône ☁️
:::

## Premier contact avec AnythingLLM

1. Ouvrir l'application
2. Créer un espace (`+`)
3. Paramètres (⚙️) → "Paramètres du chat"
4. Choisir **Ollama** comme fournisseur
5. Sélectionner votre modèle

## Tester l'interaction

- Créer un "New Thread"
- Poser une question : "Qui es-tu?"
- Observer la réponse

::: {.fragment}
⏸️ **PAUSE TECHNIQUE** (5 min)

*Tout le monde a pu interagir avec son modèle?*
:::

## Choisir le bon modèle

::: {.callout-important}
**Principe écologique :** adapter le modèle à la tâche
:::

| Tâche | Modèle recommandé |
|-------|-------------------|
| Simple (traduction, résumé) | `gemma3:1b` |
| Intermédiaire (analyse) | `qwen3:8b` |
| Complexe (évaluation) | `gpt-oss:120b-cloud` |

# Deuxième partie : Paramétrage {background-color="#2C3E50"}

## La température : concept clé

::: {.r-fit-text}
**Contrôle le degré de prévisibilité des réponses**
:::

::: {.incremental}
- Échelle : 0 à 2 (usage courant : 0 à 1)
- Modifie la distribution de probabilités
- Impact direct sur la créativité vs cohérence
:::

## Température : échelle visuelle

```
0.0 ────────────── 0.5 ────────────── 1.0 ────────────── 2.0
│                   │                   │                   │
Déterministe    Équilibré          Créatif          Chaotique
Précis          Standard           Varié            Imprévisible
Répétitif       Cohérent          Diversifié        Incohérent
```

## Température basse (0.0 - 0.3)

✅ **Idéal pour :**

- Correction grammaticale
- Réponses factuelles
- Tâches nécessitant précision

⚠️ **Risques :**

- Réponses répétitives
- Manque de variation

## Température moyenne (0.4 - 0.7)

✅ **Idéal pour :**

- Rétroaction pédagogique
- Génération d'exercices
- Usage général en enseignement

⚠️ **Configuration par défaut** de la plupart des modèles

## Température élevée (0.8 - 2.0)

✅ **Idéal pour :**

- Brainstorming
- Créativité
- Variation stylistique

⚠️ **Risques :**

- Incohérences
- Hallucinations
- Erreurs factuelles

## Ajuster la température

**Dans AnythingLLM :**

1. Espace de travail → ⚙️
2. "Paramètres du chat"
3. "Paramètres du modèle"
4. Curseur "Temperature"

::: {.fragment}
⏸️ **PAUSE pour ajuster** (2 min)
:::

## Le message système (system prompt)

::: {.callout-important}
**Définit le comportement global du modèle**
:::

::: {.incremental}
- S'applique à tout l'espace de travail
- Différent des instructions de prompt
- Invisible pour l'utilisateur
- Configuré une seule fois
:::

## Message système vs Prompt

::: {.columns}
::: {.column width="50%"}
**Message système**

- Rôle et identité
- Règles générales
- Ton et style
- Contraintes globales
:::

::: {.column width="50%"}
**Prompt**

- Tâche spécifique
- Contexte immédiat
- Détails de la requête
- Variable à chaque fois
:::
:::

## Structure d'un message système

::: {.incremental}
1. **Rôle et expertise** : Qui est le modèle?
2. **Interlocuteur** : À qui parle-t-il?
3. **Ton** : Comment communique-t-il?
4. **Contraintes** : Quelles sont les limites?
5. **Format** : Comment structurer les réponses?
:::

## Exemple : structure minimale

```markdown
### RÔLE
Tu es un assistant pédagogique spécialisé 
en FLS...

### INTERLOCUTEUR
Tu travailles avec des enseignants 
universitaires...

### TON
Adopte un ton professionnel mais accessible...

### CONTRAINTES
Ne fournis jamais de réponses toutes faites...
```

## Configurer le message système

**Dans AnythingLLM :**

1. Espace de travail → ⚙️
2. "Paramètres du chat"
3. Section "Prompt du système"
4. Coller votre message
5. Sauvegarder

::: {.callout-tip}
Un espace = un message système = un usage spécifique
:::

## Bonnes pratiques

::: {.columns}
::: {.column width="50%"}
**✅ À faire**

- Tester et itérer
- Être spécifique
- Inclure des exemples
- Adapter au modèle
:::

::: {.column width="50%"}
**❌ À éviter**

- Instructions contradictoires
- Attentes irréalistes
- Jargon excessif
- Messages trop longs
:::
:::

# Troisième partie : Exercice pratique {background-color="#2C3E50"}

## Objectif de l'exercice

::: {.r-fit-text}
**Comparer deux approches d'évaluation**
:::

::: {.incremental}
- Même modèle (`gpt-oss:120b-cloud`)
- Deux configurations différentes
- Même texte étudiant
- Observer l'impact des paramètres
:::

## Créer deux espaces

**Espace 1 : "Correcteur strict"**

- Température : 0.2
- Message système : précision grammaticale

**Espace 2 : "Rétroaction bienveillante"**

- Température : 0.7
- Message système : encouragement et progression

## Ressources GitHub

::: {.callout-note}
**Tout est disponible ici :**

[github.com/pbriss7/Atelier-Ollama-AnythingLLM](https://github.com/pbriss7/Atelier-Ollama-AnythingLLM)
:::

Vous y trouverez :

- Les deux messages système (.txt)
- Le texte étudiant (.txt)
- Ce document de présentation

## Instructions pour l'exercice

1. Créer les deux espaces dans AnythingLLM
2. Configurer température et message système
3. Copier le texte étudiant depuis GitHub
4. Soumettre dans les deux espaces
5. Comparer les réponses

::: {.fragment}
⏸️ **TEMPS D'EXERCICE** (15 min)
:::

## Texte étudiant (extrait)

> Les réseaux sociaux est un sujet très important aujourd'hui. Beaucoup de jeunes les utilisent chaque jour pour communiquer avec ses amis et sa famille...

::: {.callout-tip}
**Contexte :** Production B1-B2, sujet "Réseaux sociaux : avantages et inconvénients", 250-300 mots attendus
:::

## Discussion : observations

**Questions de réflexion :**

::: {.incremental}
- Quelles différences avez-vous observées?
- Quelle approche préférez-vous? Pourquoi?
- Comment adapteriez-vous ces configurations?
- Quels usages envisagez-vous dans vos cours?
:::

# Conclusion {background-color="#2C3E50"}

## Points clés à retenir

::: {.incremental}
1. **Ollama + AnythingLLM** = solution éthique et gratuite
2. **Température** = curseur créativité/précision
3. **Message système** = comportement global du modèle
4. **Adaptation** = choisir le bon outil pour la tâche
:::

## Cas d'usage en enseignement

::: {.columns}
::: {.column width="50%"}
**Préparation de cours**

- Génération d'exercices
- Simplification de textes
- Idées d'activités
:::

::: {.column width="50%"}
**Évaluation**

- Rétroaction personnalisée
- Analyse d'erreurs
- Suggestions d'amélioration
:::
:::

## Prochaines étapes

::: {.incremental}
1. Explorer d'autres modèles
2. Créer vos propres messages système
3. Tester avec vos contenus de cours
4. Partager vos expériences
:::

::: {.fragment}
::: {.callout-note}
**Ressources :** [github.com/pbriss7/Atelier-Ollama-AnythingLLM](https://github.com/pbriss7/Atelier-Ollama-AnythingLLM)
:::
:::

## Questions et discussion {.smaller}

::: {.r-fit-text}
**Merci de votre participation!**
:::

Contact : pascal.brissette@mcgill.ca

---

::: {.callout-tip}
## Pour aller plus loin

- Documentation Ollama : ollama.com/docs
- Documentation AnythingLLM : docs.anythingllm.com
- Bibliographie complète : voir document PDF
:::
```

**Points clés de cette adaptation :**

1. **Structure chronologique** claire avec sections colorées
2. **Pauses techniques** explicites pour synchroniser le groupe
3. **Visuels simplifiés** (pas de surcharge d'information)
4. **Éléments interactifs** (incremental, fragments)
5. **Lien GitHub** intégré à plusieurs endroits
6. **Timing respecté** avec les 90 minutes prévues

**Notes d'utilisation :**

- Remplace `images/logo.png` par ton logo institutionnel si tu en as un
- Les captures d'écran sont référencées mais tu devras les montrer en direct
- Le fichier suppose que tu as